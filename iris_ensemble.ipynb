{
 "cells": [
  {
   "cell_type": "raw",
   "id": "377d6eee",
   "metadata": {},
   "source": [
    "Week 9\n",
    "Batch 1\n",
    "Name: Shriya Bhat\n",
    "220968020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2d7b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn import metrics  \n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa16e466",
   "metadata": {},
   "source": [
    "- Ensemble Learning helps improve machine learning results by combining several models to improve predictive performance compared to a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b44705b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm         Species\n",
       "0              5.1           3.5            1.4           0.2     Iris-setosa\n",
       "1              4.9           3.0            1.4           0.2     Iris-setosa\n",
       "2              4.7           3.2            1.3           0.2     Iris-setosa\n",
       "3              4.6           3.1            1.5           0.2     Iris-setosa\n",
       "4              5.0           3.6            1.4           0.2     Iris-setosa\n",
       "..             ...           ...            ...           ...             ...\n",
       "145            6.7           3.0            5.2           2.3  Iris-virginica\n",
       "146            6.3           2.5            5.0           1.9  Iris-virginica\n",
       "147            6.5           3.0            5.2           2.0  Iris-virginica\n",
       "148            6.2           3.4            5.4           2.3  Iris-virginica\n",
       "149            5.9           3.0            5.1           1.8  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Iris.csv')\n",
    "df=df.drop(columns=['Id'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6997b45b",
   "metadata": {},
   "source": [
    "<b> Max Voting / Voting Classifier </b>\n",
    "<br>\n",
    "- The max voting method is generally used for classification problems. In this technique, multiple models are used to make predictions for each data point. The predictions by each model are considered as a ‘vote’. The predictions which we get from the majority of the models are used as the final prediction.\n",
    "\n",
    "- A Voting Classifier is a machine learning model that trains on an ensemble of numerous models and predicts an output (class) based on their highest probability of chosen class as the output. It simply aggregates the findings of each classifier passed into Voting Classifier and predicts the output class based on the highest majority of voting. The idea is instead of creating separate dedicated models and finding the accuracy for each them, we create a single model which trains by these models and predicts output based on their combined majority of voting for each output class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff820d81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((150, 4), (150,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le=LabelEncoder()\n",
    "scaler=StandardScaler()\n",
    "df['Species']=le.fit_transform(df['Species'])\n",
    "x=df.iloc[:,0:4]\n",
    "y=df['Species']\n",
    "x=scaler.fit_transform(x)\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris() \n",
    "X = iris.data[:, :4] \n",
    "Y = iris.target \n",
    "X.shape,Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49c759a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e71706ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = tree.DecisionTreeClassifier(random_state=1)\n",
    "model2 = RandomForestClassifier(n_estimators = 200)\n",
    "model3 = KNeighborsClassifier(n_neighbors=7)\n",
    "model = VotingClassifier(estimators=[('dt', model1), ('rf', model2), ('kn',model3)], voting='hard')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93742989",
   "metadata": {},
   "source": [
    "<b> Hard Voting</b>: In hard voting, the predicted output class is a class with the highest majority of votes i.e the class which had the highest probability of being predicted by each of the classifiers. Suppose three classifiers predicted the output class(A, A, B), so here the majority predicted A as output. Hence A will be the final prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "86194b4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9333333333333333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,y_train)\n",
    "model.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f1580a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(x_train,y_train)\n",
    "model1.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "443e8148",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit(x_train,y_train)\n",
    "model2.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82eb8c49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.fit(x_train,y_train)\n",
    "model3.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22929a46",
   "metadata": {},
   "source": [
    "- Trying hard voting with other model combos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "611b6931",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size = 0.20,random_state = 42) \n",
    "# Ensemble of Models \n",
    "estimator = [] \n",
    "estimator.append(('LR',LogisticRegression(solver ='lbfgs',multi_class ='multinomial',max_iter = 200))) \n",
    "estimator.append(('SVC', SVC(gamma ='auto', probability = True))) \n",
    "estimator.append(('DTC', DecisionTreeClassifier())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fbc6133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Voting Classifier with hard voting \n",
    "hard_voting = VotingClassifier(estimators = estimator, voting ='hard') \n",
    "hard_voting.fit(X_train, y_train) \n",
    "y_pred = hard_voting.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7df9b78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard Voting Score  1\n"
     ]
    }
   ],
   "source": [
    "#accuracy_score metric to predict Accuracy \n",
    "score = accuracy_score(y_test, y_pred) \n",
    "print(\"Hard Voting Score % d\" % score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5c6cc1",
   "metadata": {},
   "source": [
    "<b>Soft Voting</b>: In soft voting, the output class is the prediction based on the average of probability given to that class. Suppose given some input to three models, the prediction probability for class A = (0.30, 0.47, 0.53) and B = (0.20, 0.32, 0.40). So the average for class A is 0.4333 and B is 0.3067, the winner is clearly class A because it had the highest probability averaged by each classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "489fd633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier with soft voting \n",
    "soft_voting = VotingClassifier(estimators = estimator, voting ='soft') \n",
    "soft_voting.fit(X_train, y_train) \n",
    "y_pred = soft_voting.predict(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2798624b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Soft Voting Score  1\n"
     ]
    }
   ],
   "source": [
    "# Using accuracy_score \n",
    "score = accuracy_score(y_test, y_pred) \n",
    "print(\"Soft Voting Score % d\" % score) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fff2fee0",
   "metadata": {},
   "source": [
    "In practical the output accuracy will be more for soft voting as it is the average probability of the all estimators combined, as for our basic iris dataset we are already overfitting, so there won’t be much difference in output."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0725c289",
   "metadata": {},
   "source": [
    "### Maxvoting result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2e2711ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 2, 0, 2, 1, 0, 2, 0, 1, 1, 1, 2, 2, 0, 0, 2, 2, 0, 0, 1, 2,\n",
       "       0, 1, 1, 2, 1, 1, 1, 2])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=model.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "97d17085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [1., 0., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred1=model1.predict_proba(x_test)\n",
    "y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "daaab8fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.53 , 0.47 ],\n",
       "       [0.   , 0.005, 0.995],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.005, 0.77 , 0.225],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.04 , 0.96 ],\n",
       "       [0.995, 0.005, 0.   ],\n",
       "       [0.02 , 0.935, 0.045],\n",
       "       [0.   , 0.995, 0.005],\n",
       "       [0.   , 0.675, 0.325],\n",
       "       [0.   , 0.005, 0.995],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.995, 0.005, 0.   ],\n",
       "       [0.   , 0.05 , 0.95 ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [1.   , 0.   , 0.   ],\n",
       "       [0.   , 0.76 , 0.24 ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.   , 1.   ],\n",
       "       [0.   , 0.99 , 0.01 ],\n",
       "       [0.   , 1.   , 0.   ],\n",
       "       [0.   , 0.985, 0.015],\n",
       "       [0.   , 0.   , 1.   ]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred2=model2.predict_proba(x_test)\n",
    "y_pred2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "3c268747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.28571429, 0.71428571],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.57142857, 0.42857143],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.71428571, 0.28571429],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.28571429, 0.71428571],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.57142857, 0.42857143],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_pred3=model3.predict_proba(x_test)\n",
    "y_pred3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47cf876d",
   "metadata": {},
   "source": [
    "<b>_Averaging_ </b><br>\n",
    "Multiple predictions are made for each data point in averaging. In this method, we take an average of predictions from all the models and use it to make the final prediction. \n",
    "- The simplest way to develop a model averaging ensemble in Keras is to train multiple models on the same dataset then combine the predictions from each of the trained models.\n",
    "- The scikit-learn class provides the `make_blobs()` function that can be used to create a multi-class classification problem with the prescribed number of samples, input variables, classes, and variance of samples within a class.\n",
    "\n",
    "We use this problem with 500 examples, with input variables to represent the x and y coordinates of the points and a standard deviation of 2.0 for points within each group. We will use the same random state to ensure that we always get the same 500 points.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827fc63e",
   "metadata": {},
   "source": [
    "directly for probablity of classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9c7f5b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.27190476, 0.72809524],\n",
       "       [0.        , 0.00166667, 0.99833333],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.00166667, 0.59      , 0.40833333],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.20380952, 0.79619048],\n",
       "       [0.99833333, 0.00166667, 0.        ],\n",
       "       [0.00666667, 0.97833333, 0.015     ],\n",
       "       [0.        , 0.99833333, 0.00166667],\n",
       "       [0.        , 0.79642857, 0.20357143],\n",
       "       [0.        , 0.00166667, 0.99833333],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.99833333, 0.00166667, 0.        ],\n",
       "       [0.        , 0.11190476, 0.88809524],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.77714286, 0.22285714],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.99666667, 0.00333333],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.995     , 0.005     ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Averaging\n",
    "y_pred_avg=(y_pred1+y_pred2+y_pred3)/3\n",
    "y_pred_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8ad868c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.21614286, 0.78385714],\n",
       "       [0.        , 0.0015    , 0.9985    ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.0015    , 0.431     , 0.5675    ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.12628571, 0.87371429],\n",
       "       [0.9985    , 0.0015    , 0.        ],\n",
       "       [0.006     , 0.9805    , 0.0135    ],\n",
       "       [0.        , 0.9985    , 0.0015    ],\n",
       "       [0.        , 0.84535714, 0.15464286],\n",
       "       [0.        , 0.0015    , 0.9985    ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.9985    , 0.0015    , 0.        ],\n",
       "       [0.        , 0.07214286, 0.92785714],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [1.        , 0.        , 0.        ],\n",
       "       [0.        , 0.84228571, 0.15771429],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.        , 1.        ],\n",
       "       [0.        , 0.997     , 0.003     ],\n",
       "       [0.        , 1.        , 0.        ],\n",
       "       [0.        , 0.9955    , 0.0045    ],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Weighted averaging\n",
    "y_pred_wavg=(0.5*y_pred1+0.3*y_pred2+0.2*y_pred3)\n",
    "y_pred_wavg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac8f289",
   "metadata": {},
   "source": [
    "directly for classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3e266f8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 1.66666667, 2.        , 0.        , 2.        ,\n",
       "       1.33333333, 0.        , 1.66666667, 0.        , 1.        ,\n",
       "       1.        , 1.        , 2.        , 2.        , 0.        ,\n",
       "       0.        , 2.        , 2.        , 0.        , 0.        ,\n",
       "       1.        , 2.        , 0.        , 1.        , 1.        ,\n",
       "       2.        , 1.        , 1.        , 1.        , 2.        ])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred1=model1.predict(x_test)\n",
    "Y_pred2=model2.predict(x_test)\n",
    "Y_pred3=model3.predict(x_test)\n",
    "Y_AVG=(Y_pred1+Y_pred2+Y_pred3)/3\n",
    "Y_AVG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "247cb920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1. , 1.7, 2. , 0. , 2. , 1.5, 0. , 1.8, 0. , 1. , 1. , 1. , 2. ,\n",
       "       2. , 0. , 0. , 2. , 2. , 0. , 0. , 1. , 2. , 0. , 1. , 1. , 2. ,\n",
       "       1. , 1. , 1. , 2. ])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_WAVG=(0.5*Y_pred1+0.3*Y_pred2+0.2*Y_pred3)\n",
    "Y_WAVG"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
